{"data":{"markdownRemark":{"id":"491452b0-b10f-5584-92fa-5100a7884434","html":"<p>Zec is renderer that wraps the D3D12 API. The primary goal is to provide example implementations of various computer graphics techniques such as clustered shading, PBR shading, etc. and the secondary goal is to do it efficiently using a simple, thin abstraction around D3D12.</p>\n<p>Currently, the following implementations have been created, in part as a way of <a href=\"https://en.wikipedia.org/wiki/Eating_your_own_dog_food\">dogfooding</a> my rendering abstraction:</p>\n<ul>\n<li>Image based lighting with multiple scattering (see description below for <a href=\"#bae\">bae</a> and <a href=\"https://bruop.github.io/ibl\">this blog post</a>)</li>\n<li>ISPC accelerated view frustum culling, as documented in <a href=\"https://bruop.github.io/improved_frustum_culling/\">another blog post</a></li>\n<li>Clustered forward shading using compute shaders</li>\n</ul>\n<h3>Clustered Forward Shading</h3>\n<p>Largely based off <a href=\"http://www.cse.chalmers.se/~uffe/clustered_shading_preprint.pdf\">Olsson et al, 2012</a>, this implementation uses compute shaders to populate a buffer containing per-cluster index lists, which are then used to index into the global light lists.</p>\n<p>The current implementation supports binning of both point lights and spot lights using clusters defined as AABBs in view-space. The intersection test used for the spot lights is based of <a href=\"https://bartwronski.com/2017/04/13/cull-that-cone/\">Bart Wronski‚Äôs excellent blog post</a>, which works well with Olsson‚Äôs view-space z-partitioning scheme which attempts to maintain clusters that are as cubical as possible.</p>\n<p>One difference from Olsson‚Äôs paper is that I implemented a two-phase partitioning scheme such that the clusters between the near-plane and some user defined ‚Äúmid-plane‚Äù use a linear partitioning scheme, while those beyond the mid-plane use the Olsson partitioning scheme. The Olsson scheme produces very small clusters close to the camera, and using a linear scheme (while providing a worse fit for the bounding sphere tests) provides about a 30% memory reduction while still keeping the clusters small in view space.</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a80e868d81115b6193b4507887c1c86e/0d4f8/clustered_debug_forward.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAC4jAAAuIwF4pT92AAACpElEQVQoz2Mw0DKztvUMcgvICPA3tDNs7unsr2tzt7ExtbZlYGCQFpTWVdJrmlJeWpCrLCwrJikgIyNtbu1obuagoqLGoCavbW7hoi6jkxIaauKi2zWhuyKjWEFG3t3fn4OTsS69uKuhdeqMzu78OjVJJXk1aVlVcXNrextrdxkpNQYlBW07Gx8DPc2igtSALI/lK+YVxCaaGholpiSnpXiU5cbW1dROqq1a1DLB1tBGxUAxrjQ4LD46JDApIiSLQUZK1cLcTZCPLzQ6cPqWnsVLZ3uamXu7ulRnpqWF+KiqSPn6+Ya4OU+q7rQ3dvSKct9xdkNhdVFkeFp722wGYWFJfQMLNj4297jIFz/vr1k5z8HMMik0prusNNTFVd/QyMDYzMZEe3H/VC83j4LWxBOXtqVnp3v7hvV0z2SQlBdX1lBzDLOMy447fGRrX31RhktAUECAu4NDTFigrpGBobp2plt4a8VMP/cIl3C3GVP7Y6PibMytCzLyGfildEUl5RVVFZQVZATZWPWkJaINff3TguTVlEOcEhiYmVx0NFv884szt8TGb1DQiLUzcXQL99RIMFcLN2Ng5lZiZuFgAANmZiZmBgYTXaPy7CQnB8sV8xalZEdkpgWY6mq5BiywC99la57lbRGkYaErEqcrkW/JwMTMDtTGyMjIysLMyMgAhBqmGnEB9s5W+r1t+Q01OTWdGUbWWi4eDVpW/U56QWaqdopKKkLmknzuyiCNTCxM3AJcvELc7FysQD6nImdEksOaBTNXzp91bu+hs5f3ymjoyksCQ7rExcBfW8VUR9tE1lyRy0GWQUBAQExKTERMWNdcU9dcg5eLT8VMKSDDPTY0ID0lua25PS8vW13DWkczINYv18bIRU/H1NrKVc/CSNxcGQAht7jhBgwGhQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Shaded view. There are 1024 point lights and 128 spot lights distributed randomly throughout the scene\"\n        title=\"Shaded view. There are 1024 point lights and 128 spot lights distributed randomly throughout the scene\"\n        src=\"/static/a80e868d81115b6193b4507887c1c86e/eefce/clustered_debug_forward.png\"\n        srcset=\"/static/a80e868d81115b6193b4507887c1c86e/dfaee/clustered_debug_forward.png 180w,\n/static/a80e868d81115b6193b4507887c1c86e/4d463/clustered_debug_forward.png 360w,\n/static/a80e868d81115b6193b4507887c1c86e/eefce/clustered_debug_forward.png 720w,\n/static/a80e868d81115b6193b4507887c1c86e/dabea/clustered_debug_forward.png 1080w,\n/static/a80e868d81115b6193b4507887c1c86e/87339/clustered_debug_forward.png 1440w,\n/static/a80e868d81115b6193b4507887c1c86e/0d4f8/clustered_debug_forward.png 1600w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Shaded view. There are 1024 point lights and 128 spot lights distributed randomly throughout the scene</figcaption>\n  </figure>\n<figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2423ccdea66a1f4a3fa9a205840ecc5f/0d4f8/clustered_debug_view.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAC4jAAAuIwF4pT92AAACZklEQVQozx1R21LaUBTNL7TvtDAKRpCEkIQkICEnCdZbRaniBVAcjLa2UztDq7XKRQTJ5VxAO51pO9OHPraf0J/raWf27NkPe6291tpMuoG5YxI/w4kWmjsl4S4O+VBsTuaeXzzm9UeaLax3c2VkgBHIjyx1YKU6C5GLhSfn84suI++idINIVSxVCX9Mkq9IpE3pcKxLwl8noYcH9gKLNZxbR/IuzpYCfSmwuY4dv9aXA0Y8wNoGypVgZhexZyT+lrDvyJwzZj8Pp3/3Qg8e2w5mPmDhEPMnY2UH51egJfSK7JWZHTBSDQHbNwzX1AapIxy5GqvtW2Ub8V/62T/vo79up8duyEfJnqtWA7GO1S1sSj072Qb6iMmVkFH07UTbmv3EOyR+OuY7XrbsJ8+96M/hFPSnAp8KUfp9c+0uXSPZDWjmhgUwkuqYAcC15H4xfA74a2pBqhFhH2ubKPEGRW5Q+JvLncCC7WsNv7Di5595tKzs0DDuaDqMJd4U+R41YAA3Vwoyu0TbhPIejl6jp9/d0A+PbUFL7CsVnD7AJvuR7gPg0eNUwn9w7FK3KRKqW0jaJ/R5Ug0nXyPuNBCr3kwL5haGwiHiXhJT6NBoTH00vwrlGmbsVNfmO7o9ml+DWvlf5uomVCpIL45AYSRXvFgLiXWY2fYpaXYtyC8HVKayBbkTzJi6C2xIuy0PjGKQX8Wg4BnAyy96KWcy1b6PXd4LzlhfoaImWoUOuLCE5PpEaE6YjHooFRw1UVVn9xTxIJNpaPE9RWqkjSZbdqI7TqThsC8cST/iFp00aAqWkzYdbslJ2c5f6SzqEBWXOv8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Clustered Shading Debug view. There are 1024 point lights and 128 spot lights distributed randomly throughout the scene\"\n        title=\"Clustered Shading Debug view. There are 1024 point lights and 128 spot lights distributed randomly throughout the scene\"\n        src=\"/static/2423ccdea66a1f4a3fa9a205840ecc5f/eefce/clustered_debug_view.png\"\n        srcset=\"/static/2423ccdea66a1f4a3fa9a205840ecc5f/dfaee/clustered_debug_view.png 180w,\n/static/2423ccdea66a1f4a3fa9a205840ecc5f/4d463/clustered_debug_view.png 360w,\n/static/2423ccdea66a1f4a3fa9a205840ecc5f/eefce/clustered_debug_view.png 720w,\n/static/2423ccdea66a1f4a3fa9a205840ecc5f/dabea/clustered_debug_view.png 1080w,\n/static/2423ccdea66a1f4a3fa9a205840ecc5f/87339/clustered_debug_view.png 1440w,\n/static/2423ccdea66a1f4a3fa9a205840ecc5f/0d4f8/clustered_debug_view.png 1600w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Clustered Shading Debug view. There are 1024 point lights and 128 spot lights distributed randomly throughout the scene</figcaption>\n  </figure></p>\n<p>One thing to note is that I used 32-byte <code class=\"language-text\">uint</code>s to store light indices, but this is overkill for the number of lights I expect to support. I could easily get away with 16-bits for the index list entries BUT my laptop‚Äôs 960m lacks the feature support for 16-bit arithmetic üò¢</p>\n<h3>ISPC Accelerated View Frustum Culling</h3>\n<p>Most of the details are in two blog posts on this very site (<a href=\"https://bruop.github.io/frustum_culling/\">part 1</a>, and <a href=\"https://bruop.github.io/improved_frustum_culling/\">part 2</a>), but to summarize, the view culling transforms model-space AABBs to view space and performs a check using the <a href=\"https://en.wikipedia.org/wiki/Hyperplane_separation_theorem\">separating axis theorem</a> against the view frustum to determine whether the object is in view or not. <a href=\"https://ispc.github.io/\">ISPC</a> is used to vectorize the system and test 8 AABBs at once.</p>\n<p>For 10,000 AABBs, <strong>the system can produce a visibility list in about 0.3ms</strong> using a single core on my i5 6600k.</p>\n<p>Here‚Äôs a graphic of how this reduces wasted vertex work on the GPU as well, as without culling the GPU ends up spending time executing vertex shader work without any corresponding fragment/pixel shader output:</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3ca5cae4ffca18e8e6581fa3e6609714/973bc/unculled_occupancy.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 8.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAIAAADXZGvcAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAUElEQVQI12XKwQ2AIAxAURYETdygrWElWpLiUaU6o8hJQ/LyT98RTQAe8dsAEFpjXFaasQ/0H/rjHRu/6sA4mXCVfGm+N6marTRyFj60Sbs+LzE7GV5g3h0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Occupancy without culling\"\n        title=\"Occupancy without culling\"\n        src=\"/static/3ca5cae4ffca18e8e6581fa3e6609714/eefce/unculled_occupancy.png\"\n        srcset=\"/static/3ca5cae4ffca18e8e6581fa3e6609714/dfaee/unculled_occupancy.png 180w,\n/static/3ca5cae4ffca18e8e6581fa3e6609714/4d463/unculled_occupancy.png 360w,\n/static/3ca5cae4ffca18e8e6581fa3e6609714/eefce/unculled_occupancy.png 720w,\n/static/3ca5cae4ffca18e8e6581fa3e6609714/dabea/unculled_occupancy.png 1080w,\n/static/3ca5cae4ffca18e8e6581fa3e6609714/87339/unculled_occupancy.png 1440w,\n/static/3ca5cae4ffca18e8e6581fa3e6609714/973bc/unculled_occupancy.png 2292w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Occupancy without culling</figcaption>\n  </figure></p>\n<p>With culling, the wasted work is reduced greatly:</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3fb1275c8d6ad72cc051d18bb13ee936/9b4a4/culled_occupancy.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 8.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAIAAADXZGvcAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAUklEQVQI1zWICQrAIAwEfbvxeIIJaGyl1uOVNRZhWGZHgbeCM+AAvNGym33/ctDaHnZRNAuNQvOmfuHI2DL2jC/TkpZCjculdMaaxBuvGJ4YKn+HHEQ+yuKkKwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Occupancy with culling\"\n        title=\"Occupancy with culling\"\n        src=\"/static/3fb1275c8d6ad72cc051d18bb13ee936/eefce/culled_occupancy.png\"\n        srcset=\"/static/3fb1275c8d6ad72cc051d18bb13ee936/dfaee/culled_occupancy.png 180w,\n/static/3fb1275c8d6ad72cc051d18bb13ee936/4d463/culled_occupancy.png 360w,\n/static/3fb1275c8d6ad72cc051d18bb13ee936/eefce/culled_occupancy.png 720w,\n/static/3fb1275c8d6ad72cc051d18bb13ee936/dabea/culled_occupancy.png 1080w,\n/static/3fb1275c8d6ad72cc051d18bb13ee936/87339/culled_occupancy.png 1440w,\n/static/3fb1275c8d6ad72cc051d18bb13ee936/9b4a4/culled_occupancy.png 2274w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Occupancy with culling</figcaption>\n  </figure></p>\n<h3>Render Pass Abstraction</h3>\n<p>Zec also contains an optional ‚ÄúRender Pass‚Äù abstraction (but it‚Äôs not necessary) that will manage pass resource creation and transitions between passes. For instance, if you have a depth pre-pass that ‚Äúoutputs‚Äù a depth buffer and other passes mark as an ‚Äúinput‚Äù that will be sampled from pixel or fragment shaders, the render pass system will insert the appropriate resource transition at the beginning of the first pass that consumes the depth buffer ‚Äúautomatically‚Äù.</p>\n<p>Additionally, passes can submit work on the asynchronous compute queue and the abstraction will submit that work separately and even insert cross queue barriers when subsequent passes use the outputs. However, I haven‚Äôt robustly tested this part of the system yet and I know that it currently breaks when the resources are transitioned using a command list created from the compute queue.</p>\n<p>Future plans include:</p>\n<ul>\n<li>Better support for async compute</li>\n<li>Multi-threaded command list recording. Each pass already gets its own command list, but I haven‚Äôt yet introduced any threading into the library or application.</li>\n<li>Better support for multiple sets of passes. Right now each list of passes is it‚Äôs own heavyweight structure, making it annoying to support switching between them during runtime. It‚Äôd be nicer to have a pool of passes and then lightweight lists that describe recording of commands.</li>\n</ul>\n<h2>Bruno‚Äôs Awful Examples (bae)</h2>\n<p>Similar to Zec, but this project used BGFX to abstract away OpenGL/DirectX 11. Development ended in late September 2019.</p>\n<p>The examples include:</p>\n<ol>\n<li>Tone Mapping</li>\n<li>Forward Rendering</li>\n<li>Deferred Rendering</li>\n<li>Image Based Lighting</li>\n<li>Cascaded Shadow Mapping</li>\n</ol>\n<h3>Tone Mapping</h3>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/97d98e9c878f44b6813ca81a7a8604ae/f3baa/01-tonemapping.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADMklEQVQozyXQ3U+bVRwH8Oc/EFayjlo3ICIwC+v76/PSPu3TPn2HtaVulr6xtqFAKWUwXqRI42TCHKMMtsRoZkzmYjTxymuNF97qzW5M3N1c4g22M0ZZz9eTefHNOTkn5/M7vx8zERT+0muGWxbtcHtoQP0iEbL9/esPt8g3zQK+Ppwh9+pT+O7hGn58vILvP5nGo0YS95eihAb1vPffoTHLk6FRy8+q8wNPL/b3thk5dvnJJX/yJ43g+UWhVD5nDW+1H7w/RXJXZDQqcbKYC6Kcj2KlNI6jWhTNhRAOF0LkQS2MzYx4+oZa/XuvSv1Mqez9QzOgesG4A+yzPqP2t0Gr7qlCpXo+Nni+dWclSWIxGZzDQOwOAwIRH+ZyEdyv+nFYjaBZCZLjagjrKeHluZ7utlLR1VZ0v/bn6JvqNlO8IndM2pGO9mJ/x2caPL2Rdv+zU5sk8ckw4jGZTKejFAvjg52bOKiXsb9ewN25ADmqBLD2Lv/yrOLMSc+Z7pPurq6TkT7a8trsJIIyC86qQU7WoVkNY2/xMnYWE+RgOY7j99I4WMvh2893cLi7ioOlOO6WfaQ5H8A6BftfP9u6QKM+19PSD/e1mMr0BOE5A+FYHXFYR0kt5Sa3F2PkmA79s+0cefTFp3j45Veo5qIoJSXszUWwPxsgd8p+7JW8ZCvj6tSnXJ3NlLOznXGfMslEGCE/j2DABcnrRCQsoZhPYKGYQKU0hXsf3cDuZhlH9SwqSQFbWTf2Z3zYLXrJXkHCxyUvbpd8FH91BiZAEb8kwCs6aOzwiCzcHicknweii0XIZYBoHQNvGkHYx6KxkseH11OkMRvDdiFAtrIS2UqLpJF2kZtZkTB+twM+Crl5C3i7AU6HEU7OBMllh8DZMZsdx62NEpauTaCYiSN5NY5SKY3l5TI21+dQX53BRi2PjfmrWC2MgxFZPUQKiJz5f8yuo6sBgk0Lwa6HxBuRisvIxKVXe7PxEhw2PVxOKx2TiHeSURSKaVTmr+F6rQhGEuhvKOih4W06CFb6wPg27CYNOIp6KOK0jYIza8DS1h0WLVgK8rSwgxY0m+gda4bodiIYlPEfNe+r2essM7oAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Image rendered using the Uchimura tone mapping operator\"\n        title=\"Image rendered using the Uchimura tone mapping operator\"\n        src=\"/static/97d98e9c878f44b6813ca81a7a8604ae/eefce/01-tonemapping.png\"\n        srcset=\"/static/97d98e9c878f44b6813ca81a7a8604ae/dfaee/01-tonemapping.png 180w,\n/static/97d98e9c878f44b6813ca81a7a8604ae/4d463/01-tonemapping.png 360w,\n/static/97d98e9c878f44b6813ca81a7a8604ae/eefce/01-tonemapping.png 720w,\n/static/97d98e9c878f44b6813ca81a7a8604ae/dabea/01-tonemapping.png 1080w,\n/static/97d98e9c878f44b6813ca81a7a8604ae/f3baa/01-tonemapping.png 1280w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Image rendered using the Uchimura tone mapping operator</figcaption>\n  </figure></p>\n<p>While the BGFX repo already contains an example of HDR tone-mapping, it is implemented using a chain of down-sampled textures and operators like the Uncharted and Reinhard curves. I was interested in implementing a more modern approach, so my implementation has a few differences.</p>\n<p>It uses a compute shader to construct a luminance histogram of the input HDR framebuffer, and another that performs a weighted average using the histogram to obtain an average luminance.</p>\n<p>The average luminance is then used to create an exposure value which we can then use to scale our input luminance, which we then feed into different tone map operators. The example includes a few different operators:</p>\n<ul>\n<li><a href=\"http://www.cs.utah.edu/~reinhard/cdrom/tonemap.pdf\">Reinhard</a> with variable white point</li>\n<li>Unreal, based off ACES with built in gamma correction</li>\n<li><a href=\"http://32ipi028l5q82yhj72224m8j.wpengine.netdna-cdn.com/wp-content/uploads/2016/03/GdcVdrLottes.pdf\">Lottes</a></li>\n<li><a href=\"https://www.desmos.com/calculator/gslcdxvipg\">Uchimura</a></li>\n</ul>\n<p>For more detail and comparisons, please see the two blog posts I‚Äôve written documenting the process:</p>\n<ul>\n<li><a href=\"https://bruop.github.io/exposure/\">Automatic Exposure Using a Luminance Histogram</a></li>\n<li><a href=\"https://bruop.github.io/tonemapping/\">Tone Mapping</a></li>\n</ul>\n<h3>Forward vs. Deferred Rendering</h3>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/81bb0e0b8a6d5d319422a3d011fb9dd4/f3baa/02-forward-rendering.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADPElEQVQozw3OT2xadQAH8Bc8uU7K/7dCx5/CoED5Wwq8vpZXHq8U+mD8Ga+lBcagFGi7dW60m3NZzVzbdd2WmbglRhNNjJ6MBw8mnj3pwYsmHtTEmxcTs67TaEN+X3f/HD6U1Wr422wcfmmzml9abeYXBgv9jy8ygkqBR7mbJL2NPD56sIWvv/sWux9+iuv5NSwmc2Q2M4NOvfyvzTP1w8gY873BZPvFaNQfUaFw/DdXRPjR4gz8qqXpP4fOqI/D9nMklWBQfSdHmm8VcflGCe+93cStnQ082tnFta1NUujMoTwfO6Fp3V86nfqFSvHGkUarPKZcDPO7fXbmJ3ti+me1Xv+HYUh7zJjcZC4Xx3IjRpq353Fzr46HjRLubOfx2Zcf4+7TJ+Tdz7dwq1HqaxSKI/mg/Lly8PRz2jR8RCULU/1zDkPfGbb0uUbkhFsJ/Tft9ZNWu43eDYF093jceVbD/XIRK60ZNNYTWLqdIGuf1PDN4V1y/kK8Tyuovsc93Bez7AklbYuIZt0YT9mROZyDuM9jZjqA5soGWbwShbASQbZaw1VeQp4fQSThRXyJwcJqgnzx/j2Il4swqyl4/TpMcaOgsj2BMFUfGZs4S7hNlsRaIeL3GklKEOGsuIjQymOSP0Q0VIDdpYJYmUXlcZsslHjsrF0ibCVJzDqKRC0aEh/3EIqvRsBmfbCYVIjEnBg2aSA3nQaXiiF6kYfYSWIx28GZIRaJhAGr2xykRyXkm23UO/fgHR+BXkVhI+RALsOBSgVCyI1GweqdmHL7YbPQeM17CooYDbPoRpkZA+cIIOzjsPtmDAfbGVypT6NU6SLb24dqUAaHSoav1iXEF8KgRDoMXusHa3NBiIQg8ZPweGmoAkoIATfyAyowZjtWK+fx8GoND9o1HFwooFq4hGA6gwnVKWSMatxcTsMTkoMKGsxgxqxIhtwoshMoJCaR5oOoiwLq9lHMymSYZ8PoXqxir7uJg+V1fCC1UE1KkAeS0A0MwKxQwhY0IuCWgWLdJqQDo8gFPci/GgrpIOysEewCA8nnQPoVlipFXG+1cH+9hye1a9ifq2CJLeAsV4BO+Tq0GjVcXjV8Dgr/A61lhrvtL3hJAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Forward rendered Sponza atrium\"\n        title=\"Forward rendered Sponza atrium\"\n        src=\"/static/81bb0e0b8a6d5d319422a3d011fb9dd4/eefce/02-forward-rendering.png\"\n        srcset=\"/static/81bb0e0b8a6d5d319422a3d011fb9dd4/dfaee/02-forward-rendering.png 180w,\n/static/81bb0e0b8a6d5d319422a3d011fb9dd4/4d463/02-forward-rendering.png 360w,\n/static/81bb0e0b8a6d5d319422a3d011fb9dd4/eefce/02-forward-rendering.png 720w,\n/static/81bb0e0b8a6d5d319422a3d011fb9dd4/dabea/02-forward-rendering.png 1080w,\n/static/81bb0e0b8a6d5d319422a3d011fb9dd4/f3baa/02-forward-rendering.png 1280w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Forward rendered Sponza atrium</figcaption>\n  </figure></p>\n<p>The two examples <code class=\"language-text\">02-forward-rendering</code> and <code class=\"language-text\">03-deferred-rendering</code> are set up to be largely identical, but with a few key differences to highlight the strengths and weaknesses of forward vs deferred rendering.</p>\n<p>Both examples render a version of the <a href=\"https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0/Sponza\">Sponza scene</a> that includes textures for the ‚Äúmetallic-roughness‚Äù workflow. We use a fairly standard single-scattering BRDF:</p>\n<ul>\n<li>Trowbridge-Reitz (GGX) normal distribution</li>\n<li>Smith correlated visibility term</li>\n<li>Schlick Fresnel Approximation</li>\n</ul>\n<p>With some additional GLTF features supported:</p>\n<ul>\n<li>Occlusion texture</li>\n<li>Emissive texture</li>\n<li>Base color, emissive, metallic and roughness factors</li>\n</ul>\n<h4>Forward Rendering</h4>\n<p>The forward renderer supports up to 255 point lights in the scene, but there is no culling of the lights evaluated per draw call, so slow down happens quickly (after about 50 lights on my machine). The light data is passed using uniform arrays and evaluated through a simple for loop. We only evaluate the BRDF if the light‚Äôs incident value is zero, which we can do since we use the non-physical fall-off function from <a href=\"https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf\">Karis 2014</a>. Therefore the intensity of the lights will also have an impact on performance. At lower total intensity settings (around 10.0) my computer can handle ~150 lights in the scene before it starts dropping frames regularly.</p>\n<p>There‚Äôs also a z-prepass to reduce the amount of overdraw, which has a pretty drastic effect on performance as we don‚Äôt have any sorting of our draw calls based off depth (by default, BGFX sorts draw calls to minimize state changes).</p>\n<h4>Deferred Rendering</h4>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/77ef246d1df02838b35d47ec2bcfaead/f3baa/03-deferred.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADDUlEQVQozyWRW0wbVBjHT1tq5nQElVVhaygrIKMtG4xKEejaUWa6ja6UlpZSpFw66JCulNKxtkA62cgWM2UmzEumm4nzMmeMl2wmxrjo4oPEeHnwQU2MZvFJE598/PktPvxzzvcl53d+3zlqfmaE3IlxVk7OUMqnOHVijHw6ztzxYdLJGMX5Y6Sz40yffowLK4qjixZiBRO+YiutCyF2nJxka+EcNdkrVOWuoTLJKAtzcbLzcTKzYXxP+wj5/cyM+ZicCJEIeRgdDxMUyIU1xejGPqLr+5i9ZGZ6zURtMUxN6SrBl29jff0FVCoRJjLioaJ/J7XBenrjPXj9ATEbYT4ZIuBqxx2MMvZaF6XrNvJvmlk6/wDFs9uJFOoY+ynJ4KdXyOT+pfjxphhOxSkkJ+mNdGA+2sCUrZGpoWFeOpNjOT2MzyfQ0Chr61WUVvUsnVKslDQk1muIfBbkOZ4l9ccl/LkfWFoGdSwfJlEc4HgpQCzVTdhVSWrVT+FcjGeWfVgnBjAO9jEzp8jk72f2cifx5VZGz9ST/jlL4W6WqW8X8RfukF78HaXb0KK7oUV7VYO6rGSvQ39Tx5b3tOjfktzSonlFT6e3A3tLM80OM4GAm8P9Po7I2u6zY+ncy5M9QfbYu1BqXaHekFyUPK/ksORefV1yTbKhKDurxRN9Clt3O86+eoYTDlzdnRw+4OWI24PTsZ+mBiO76wwCfFGhf19x323Flg8UD36vePg72X8hva8V2zal/qiM/fJpDf0VPD5koK2vFmNzE23OXhzOJ3B4vdib6miqrxTgDcXWDxXb/1KU/6N46EeF4ZZY/iZm3/wPf2SzjEMjVlxRC5VeA/r2cvZYd9Pe5cYTcjM4dBCD4VF2WY0CfEfGeltMvhLYrwrzJ2L2pfT+FqjYVtyRCzY1HPJ3kJiO4PY5MTWaaCuvZtI/wMZqjAmvjRaLjcaWapT23nvdlFHFZtvnih0C1vwivbsSqatkAsOfOtKZfsLeAxhN1Tjte+mptXB6dYF3X10iOWHH5e5ip2UX/wFvhKrMnuSgWgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Composite image showing different parts of the Gbuffer and final image\"\n        title=\"Composite image showing different parts of the Gbuffer and final image\"\n        src=\"/static/77ef246d1df02838b35d47ec2bcfaead/eefce/03-deferred.png\"\n        srcset=\"/static/77ef246d1df02838b35d47ec2bcfaead/dfaee/03-deferred.png 180w,\n/static/77ef246d1df02838b35d47ec2bcfaead/4d463/03-deferred.png 360w,\n/static/77ef246d1df02838b35d47ec2bcfaead/eefce/03-deferred.png 720w,\n/static/77ef246d1df02838b35d47ec2bcfaead/dabea/03-deferred.png 1080w,\n/static/77ef246d1df02838b35d47ec2bcfaead/f3baa/03-deferred.png 1280w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Composite image showing different parts of the Gbuffer and final image</figcaption>\n  </figure></p>\n<p>Meanwhile, in the deferred case we use <strong>light volumes</strong> to calculate our shaded pixel values. We render each point light using two draw calls: one which only writes the stencil buffer, marking any pixels that we don‚Äôt want to shade, and then a second draw with the same geometry that tests against those stencil values and perform the shading, writing to the output buffer additively.</p>\n<p>The first draw draws both back and front faces and will mark pixels using the following test:</p>\n<ul>\n<li>For front facing geometry, if it fails the depth test, those pixels are occluded by scene geometry that is in front of the volume.</li>\n<li>For back facing geometry, if it passes the depth test, those pixels are beyond the light‚Äôs volume.</li>\n</ul>\n<p>In both cases we increment the stencil buffer, and use a stencil test against <code class=\"language-text\">0</code> (the starting value) for the second draw call.</p>\n<p>With this scheme, we submit 2N draw calls for N lights, but we strictly shade only pixels that fall within the light volume so we end up with significant gains in terms of the number of lights we can have in a scene. If the light volumes overlap for many pixels and many number of lights, we‚Äôll still end up with poor performance however, as our solution basically regresses to the forward rendered solution but with extra draw calls.</p>\n<p>With a lower total intensity (again, 10.0) my computer can evaluate about ~1000 lights before slowdown occurs. Above that, the CPU time required to perform all the state changes and submit the draw calls for all our lights starts to outpace our GPU‚Äôs ability to render frames.</p>\n<p>Additionally, the deferred example has no support for transparency. In our Sponza scene all the vegetation is rendered using an alpha cutoff, which we can still render to our G-Buffers. There is also no support for hardward MSAA, so AA would have to be implemented using a custom solution.</p>\n<p>Finally, the emissive lighting was applied using a full-screen quad, similar to what you‚Äôd need to do for directional lights (in fact you could probably do both in the same pass).</p>\n<h3>Physically Based Image Based Lighting</h3>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6b7135ce901f83cfc91f83cdb9935dba/f3baa/04-pbr-ibl.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADBElEQVQozx2QW29iVRiG9x9wTK0O00I79KBF3FCO+3wCNgwtBVtgD9AOlMOmRSgQLZOZtqP2GI1z5aX/ygsziYmJN8abJo6dcWJmJOt10Ysn38rKyvOt92WkCPtmlfW8WvV+/I/bNfMm4nX/e9k2yVXbxKWdIOd1A82shlLaQPtBEOc1DadVjfw0SOLHnvl2xev/47OVpesF9/x1PLLyktGM+G9hfeNnb0D4dXr6o2t22fX6omWSS9vElW2SUUXD0VddNOolZCQ/DvM8zmoGed6O49uq8t+8895fc7OOv2dnHC9F3+IrJqDzvy+ZsV+W48qLKafzT4979vV5K0nOm4lb4bAoISEFkE5ICHnuo5+L3govdg0M88LY8eHUzd3pqZsPpt6/YZdcN0yvqIz3tuTxfl4e25+L73qW+vbCTpGzxkSYJIMtDnOuWcw5HVgLzeObRzpOtjXybEfH07JGOll+3MkK405OGA8LyjvmYn8d33czeH6wgR966/iuk8ZZ08RpPU4ouGqZ4H0LCC7O4Kxq4IhWcDypoaKRp2Udx9sGXRDDs0dxfE1h+ntlMrAtUtuKkS/KSXK0t0lO2lly0lzDcT1JLtsprAte5KOf4rQWw5OH8gTy2FIwKsrksKiQkaWSxyWNPKkYhMnl0tjcXIeqSzBNBXbDwqC3i8PBLk5GNhrVHLwuBx74llBIRNGvpDGsmDgo6jgoaOgXVAyLKr60NIxKOhhdk6CqAjRNhE6lhiFTsY6NTBLVnTzKRgia8w7SrveQmb+DVjlLF9bQbZfQaVroNAo4sC30W0X06ptgVJmDToVxKopRoSxFIQlhyAoPPeBBwXMXO6H72OcWscctIG1qt4keWjlsV7bQrJfR7dYxHLYpNhiRC0IWQpD5EBQxDFWKQKOIfBARvwe81w3eMwPzk3tIsfTMrUKgyPSNPPmMIWFtLYHMRgrZXIoKIyzEqA9CmIUc9d9Okc7JvcSxiEZ8CAVZhP0rCLPL4MJeSLyfpqBiPgBJpJVoAk3EQZSj+B/AmpKu9K/YRQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Flight Helmet model rendered using image based lighting\"\n        title=\"Flight Helmet model rendered using image based lighting\"\n        src=\"/static/6b7135ce901f83cfc91f83cdb9935dba/eefce/04-pbr-ibl.png\"\n        srcset=\"/static/6b7135ce901f83cfc91f83cdb9935dba/dfaee/04-pbr-ibl.png 180w,\n/static/6b7135ce901f83cfc91f83cdb9935dba/4d463/04-pbr-ibl.png 360w,\n/static/6b7135ce901f83cfc91f83cdb9935dba/eefce/04-pbr-ibl.png 720w,\n/static/6b7135ce901f83cfc91f83cdb9935dba/dabea/04-pbr-ibl.png 1080w,\n/static/6b7135ce901f83cfc91f83cdb9935dba/f3baa/04-pbr-ibl.png 1280w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Flight Helmet model rendered using image based lighting</figcaption>\n  </figure></p>\n<p>Since I had a GLTF model loader, I figured it would be nice to be able to render them using image based lighting. BGFX already has an example for IBL, but it relies on external software to generate the pre-filtered environment maps, which was actually exactly the part I wanted to understand better. So I decided to implement IBL ‚Äúfrom scratch‚Äù using <a href=\"https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf\">Karis 2014</a> as a guide, and then augmenting the BRDF with recent work on multi-scattering BRDFs. So this example includes compute shaders for generating the BRDF LUT, pre-filtered environment map and irradiance map.</p>\n<p>I wrote an extensive overview of the implemention in <a href=\"https://bruop.github.io/ibl/\">a blog post</a>, so if you‚Äôre interested in more detail please check that out! It was a really fun project.</p>\n<h3>Cascaded Shadow Maps</h3>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/53ca6c35c4cf363b98d95c1e85131ac0/88b03/05-shadow-mapping.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.77777777777778%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADJklEQVQozx2SX2hbVQDGT6esarYmaZJ7c5N7k/sv909v0iR3adM2zdql6x+b2cWtW+xKp1YmK2VgrVrQkdbWdVjWbTLLHlYqcy/WBxEEBZGBIAjuQXxxRZwyBHGgDyqCRT2fJznwcThw+PHxfR8xdOM3IRz+nQt4/7F1Ed25JE2acbipBPJuGzqzFg52Z1Eq5hr3xHgZF5YW6PVraygdOrirZUo7it35g6LE/zTUKEgy33c3yIUfMOBubz6Nvh6XWmoEkyfKKHZlcPTxfpQHe5kKGD1cwNzsNMYrw3SyWoFl6n/bB0rfiLJ1V5PFP9ptGcTocu/rduLX1aX53eXzL0AROWrrEZw4OoQU+/D0xBMoMmfV46NYWXwJt965hpHDRZpNWZBjwq6RLuwIonovzAX/stUwiCaG0G7GcP3KEp0+PQ4+sJ+m21RUjw2j03VwbuZZVEYKuHF1FdsfrOPq5gXUFuZoJ4tDiYUp079CyPefIoaoowuU6EqEZhyFvr1ew+yZSZp2NCQUAWPlAeTTGt69cRnrb61huzaPs9UBPHe6AichQZU4Kko8ZJGDHueRdWQwIIitS7Su5drL9PjYIDKORmXBj8UXn0fl5Di23tvEudoljBWymD01iK9uf1qPg8YiXkSlAHUMmbpJhbabIm3TWSmOKSMWacXoUBFf3/kcl1Zr8LU0YW1jDldu3sJTb3yCjr4pHDo2hDs7n+HBz7+gvzsFkWtBQgrB1CKQhACLTUIDWLdrqwIyloTXXpnB1sZFHHl1GNMfn8HIUB795Ql0lCax9eFHqJ+Ly+ehMneGxEFo3Yd4NAA1xsNijBB7k5XXF3FkZACWziPob0Y+ZWLmzSp6FrrQrYo41ZvD/MpmA/bT/XvocU04RhQxnwfBh/agLSHCUMJo8TRj36N7Qba338fUM1MgHoL9gWYIwRY8wj2MaJLDk7wfN89O4ctvv2gA11gcuuhDls1J4b1QWFSaFITf62F6DCZzSaonq3A7XBAfAfET7Gltgie4FzxpQqqZ4PbmRgP24/ffoTdnIck2eiAZh8/Pw+tlDce4Rgf1ZeTaNfwPf0WGap09JEEAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Cascaded Shadow Maps\"\n        title=\"Cascaded Shadow Maps\"\n        src=\"/static/53ca6c35c4cf363b98d95c1e85131ac0/eefce/05-shadow-mapping.png\"\n        srcset=\"/static/53ca6c35c4cf363b98d95c1e85131ac0/dfaee/05-shadow-mapping.png 180w,\n/static/53ca6c35c4cf363b98d95c1e85131ac0/4d463/05-shadow-mapping.png 360w,\n/static/53ca6c35c4cf363b98d95c1e85131ac0/eefce/05-shadow-mapping.png 720w,\n/static/53ca6c35c4cf363b98d95c1e85131ac0/dabea/05-shadow-mapping.png 1080w,\n/static/53ca6c35c4cf363b98d95c1e85131ac0/87339/05-shadow-mapping.png 1440w,\n/static/53ca6c35c4cf363b98d95c1e85131ac0/88b03/05-shadow-mapping.png 1920w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Cascaded Shadow Maps</figcaption>\n  </figure></p>\n<p>Having never worked with shadow maps I figured it‚Äôd be a good idea to try and implement one of the more complicated shadow mapping algorithms, cascaded shadow mapping.</p>\n<p>The idea is simple: render many different shadow maps that cover different parts of your view frustum to maximize the shadow map density closer to the camera, allowing for fewer ‚Äúperspective aliasing‚Äù artifacts. However, the exact placement of the cascades can be simple, manual or it can be more involved.</p>\n<p>In this example, the cascades are placed by using a logarithmic placement algorithm (eq 7.5 in <a href=\"http://www.realtimerendering.com/\">RTR Vol 4</a>) and bounded using a depth reduction step (performed on the GPU using compute shaders). The min and max depth values are stored inside a 1x1 texture and read back on the CPU, which uses the data to determine each cascade‚Äôs view frustum.</p>\n<p>The view frustum is further constrained using the scene axis-aligned bounding box, to ensure that the near and far planes are beyond the scene geometry and that the left, right, top and bottom planes do not exceed the bound of the scene.</p>\n<p>This maximizes our effective shadow map resolution, but it does come with some drawbacks. For one, there‚Äôs no way for us to really ‚Äúclamp‚Äù the movement of our cascades to texel sized increments as the world space size of our texel is constantly changing, so we still experience the pixel crawl of unstabilized cascades.</p>\n<p>I‚Äôve also added percentage close filtering (PCF) using a randomly oriented poisson disk, as explained in <a href=\"https://www.realtimeshadows.com/sites/default/files/Playing%20with%20Real-Time%20Shadows_0.pdf\">this presentation by Kaysan</a>. My implementation is a bit simpler however, and I just perform the 16 taps with the same size in light space for all pixels which don‚Äôt self occlude.</p>"}}}